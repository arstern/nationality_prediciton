{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"name":"FFNN_Gender.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"id":"jWkTRfYsJUxo"},"source":["#Import required packages\n","import pandas as pd\n","import numpy as np\n","import librosa\n","import librosa.display\n","import pathlib\n","import os\n","import matplotlib.pyplot as plt\n","from sklearn.preprocessing import scale\n","import warnings\n","import glob\n","from scipy import signal\n","import tqdm\n","import tensorflow as tf\n","from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NIW40y0yJUxx","outputId":"352d2994-ea37-47b4-c917-4dc4f65edc3a"},"source":["%cd \"/content/drive/Shareddrives/CIS_519_Final_Project\""],"execution_count":null,"outputs":[{"output_type":"stream","text":["/Users/Vera/Desktop/CIS519\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"d4h3Ft7bJUxz","outputId":"6dac70b2-184f-4db2-cdda-d81ae7dccba8"},"source":["#Read audio classification file and clean\n","\n","audio_class_df = pd.read_csv(\"audioclassification_meta.csv\")\n","c_names = audio_class_df.columns.tolist()\n","c_names = c_names[0].replace(\" \", \"_\").split(\"\\t\")\n","\n","audio_class_df[c_names] = audio_class_df['VoxCeleb1 ID\\tVGGFace1 ID\\tGender\\tNationality\\tSet'].\\\n","                        str.split(\"\\t\", expand = True)\n","audio_class_df = audio_class_df[c_names]\n","\n","#Set as dictionary\n","audio_class_dict = audio_class_df.set_index(\"VoxCeleb1_ID\").T.to_dict('list')\n","\n","#View data\n","audio_class_df.head()\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>VoxCeleb1_ID</th>\n","      <th>VGGFace1_ID</th>\n","      <th>Gender</th>\n","      <th>Nationality</th>\n","      <th>Set</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>id10001</td>\n","      <td>A.J._Buckley</td>\n","      <td>m</td>\n","      <td>Ireland</td>\n","      <td>dev</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>id10002</td>\n","      <td>A.R._Rahman</td>\n","      <td>m</td>\n","      <td>India</td>\n","      <td>dev</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>id10003</td>\n","      <td>Aamir_Khan</td>\n","      <td>m</td>\n","      <td>India</td>\n","      <td>dev</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>id10004</td>\n","      <td>Aaron_Tveit</td>\n","      <td>m</td>\n","      <td>USA</td>\n","      <td>dev</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>id10005</td>\n","      <td>Aaron_Yoo</td>\n","      <td>m</td>\n","      <td>USA</td>\n","      <td>dev</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  VoxCeleb1_ID   VGGFace1_ID Gender Nationality  Set\n","0      id10001  A.J._Buckley      m     Ireland  dev\n","1      id10002   A.R._Rahman      m       India  dev\n","2      id10003    Aamir_Khan      m       India  dev\n","3      id10004   Aaron_Tveit      m         USA  dev\n","4      id10005     Aaron_Yoo      m         USA  dev"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"jyDQfEx_JUx1","outputId":"e1a6c69e-78bd-4d9a-9c0d-34b08dc47028"},"source":["def pull_id_npz(file_name):\n","    container_list = []\n","    container = np.load(file_name)\n","    container_list.append([container[key] for key in container])\n","    return container_list\n","\n","#Get irish speakers\n","%cd \"/content/drive/Shareddrives/CIS_519_Final_Project/irish_npz_files\"\n","irish_npz_dict = {file_name: pull_id_npz(file_name) for file_name in glob.glob(\"*.npz\")}\n","\n","#Get US females\n","%cd \"/content/drive/Shareddrives/CIS_519_Final_Project/usa_f_files\"\n","usaf_npz_dict = {file_name: pull_id_npz(file_name) for file_name in glob.glob(\"*.npz\")}\n","\n","#Get US males\n","%cd \"/content/drive/Shareddrives/CIS_519_Final_Project/usa_m_files\"\n","usam_npz_dict = {file_name: pull_id_npz(file_name) for file_name in glob.glob(\"*.npz\")}\n","\n","#Get all other English speaking nationalities\n","%cd \"/content/drive/Shareddrives/CIS_519_Final_Project/non_usa_eng\"\n","nonusa_npz_dict = {file_name: pull_id_npz(file_name) for file_name in glob.glob(\"*.npz\")}\n","\n","#Get all non-English speaking nationalities\n","%cd \"/content/drive/Shareddrives/CIS_519_Final_Project/non_eng\"\n","test_npz_dict = {file_name: pull_id_npz(file_name) for file_name in glob.glob(\"*.npz\")}\n","\n","#Concatenate all training data (english speaking nationalities)\n","train_npz_dict = {**irish_npz_dict, **usaf_npz_dict, **usam_npz_dict, **nonusa_npz_dict}\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/Users/Vera/Desktop/CIS519/irish_npz_files\n","/Users/Vera/Desktop/CIS519/usa_f_files\n","/Users/Vera/Desktop/CIS519/usa_m_files\n","/Users/Vera/Desktop/CIS519/non_usa_eng\n","/Users/Vera/Desktop/CIS519/non_eng\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"emZSMI3xJUx2"},"source":["#Pre-Processing: Filtering\n","\n","#Sampling rate of audio data\n","fs = 16000\n","\n","def butter_lowpass(data, lowcut = 5000, fs=16000, order = 4):\n","    '''\n","    Function: Apply lowpass butterworth filter\n","    Inputs:\n","        - data: numpy array of wave data\n","        - lowcut: cutoff frequency, default set to 5000 Hz \n","        - fs: sampling rate, default set to 16000 Hz (based on VoxCeleb data)\n","        - order: filter order, default set to 4. Larger order = sharper cutoff\n","    Output:\n","        - y: numpy array, filtered version of wave data\n","    '''\n","    nyq = 0.5 * fs\n","    low = lowcut / nyq\n","    b, a = signal.butter(order, low, btype='low')\n","    y = signal.lfilter(b, a, data)\n","    return y\n","\n","def butter_highpass(data, highcut = 75, fs=16000, order = 4):\n","    '''\n","    Function: Apply lowpass butterworth filter\n","    Inputs:\n","        - data: numpy array of wave data\n","        - highcut: cutoff frequency, default set to 75 Hz (below this is mostly noise)\n","        - fs: sampling rate, default set to 16000 Hz (based on VoxCeleb data)\n","        - order: filter order, default set to 4. Larger order = sharper cutoff\n","    Output:\n","        - y: numpy array, filtered version of wave data\n","    '''\n","    nyq = 0.5 * fs\n","    high = highcut / nyq\n","    b, a = signal.butter(order, high, btype='high')\n","    y = signal.lfilter(b, a, data)\n","    return y\n","\n","def plot_signal(data):\n","    '''\n","    Function: plot time-series signal data\n","    Inputs: \n","        - data: numpy array of wave data\n","    '''\n","    #Use librosa display to show wave plot\n","    librosa.display.waveplot(data, sr = 16000)\n","    plt.xlabel(\"Time\")\n","    plt.ylabel(\"Amplitude\")\n","    plt.show()\n","\n","def plot_fft(data, fs=16000):\n","    '''\n","    Function: plot FFT\n","    Inputs: \n","        - data: numpy array of wave data\n","        - fs: sampling frequency, default is 16000 Hz\n","    '''\n","    #Take FFT of data\n","    fft = np.fft.fft(data)\n","    #Calcualte magnitude and frequency\n","    magnitude = np.abs(fft)\n","    frequency = np.linspace(0, fs, len(magnitude))\n","    #Since symmetric, only take left side and plot\n","    left_frequency = frequency[:int(len(frequency)/2)]\n","    left_magnitude = magnitude[:int(len(frequency)/2)]\n","    plt.plot(left_frequency, left_magnitude)\n","    plt.xlabel(\"Frequency (Hz)\")\n","    plt.ylabel(\"Magnitude\")\n","    plt.title(\"FFT\")\n","    plt.show()\n","\n","def get_freq_data(data, fs = 16000, plot = False):\n","    '''\n","    Function: get frequency data of signal (magnitude and corresponding frequencies)\n","    Inputs: \n","        - data: numpy array of wave data\n","        - fs: sampling frequency, default is 16000 Hz\n","        - plot: Boolean for whether to plot or not. Default is false\n","    Outputs:\n","        left_frequency: numpy array of frequency values\n","        left_magnitude: numpy array of magnitudes corresponding to frequency values\n","    '''\n","    #Take FFT of data and calculate magnitudes and frequencies\n","    fft = np.fft.fft(data)\n","    magnitude = np.abs(fft)\n","    frequency = np.linspace(0, fs, len(magnitude))\n","    left_frequency = frequency[:int(len(frequency)/2)]\n","    left_magnitude = magnitude[:int(len(frequency)/2)]\n","    if plot == True:\n","        plot_fft(data, fs=16000)\n","    return left_frequency, left_magnitude\n","\n","def filter_signals(all_npz_dict):\n","    '''\n","    Function: Filter all signals in npz dictionaries with lowpass and highpass filters\n","    Inputs: \n","        - all_npz_dict: dictionary keyed by folders, contains lists of numpy arrays representing wave files\n","    Outputs:\n","        - filtered_npz: dictionary keyed by folders, contains list of numpy arrays representing filtered wav files\n","    '''\n","    filtered_npz = {}\n","    #Loop through all keys in dictionary\n","    for key in all_npz_dict:\n","        #Get list of all unfiltered data (all_npz_dict has two nested lists of data)\n","        unfiltered_list = all_npz_dict[key][0]\n","        filtered_list = []\n","        #Loop through all wave files\n","        for j, wave in enumerate(unfiltered_list):\n","            #Pass through lowpass and highpass filters\n","            filtered_wave = butter_lowpass(wave, 5000, 16000, 5)\n","            filtered_wave = butter_highpass(filtered_wave, 75, 16000, 5)\n","            filtered_list.append(filtered_wave)\n","        filtered_npz[key] = filtered_list\n","    return filtered_npz"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P5bvFpOzJUx3"},"source":["def get_labels(all_npz_dict, audio_class_dict):\n","    '''\n","    Function: Obtain gender and nationality labels for each folder\n","    Inputs:\n","        -all_npz_dict: dictionary keyed by folder, list of arrays representing wav files\n","        -audio_class_dict: dictionary keyed by speaker ID, contains list of all IDs belonging to speaker\n","    Outputs:\n","        - label_dict: dictionary keyed by folder, contains list of gender and nationality\n","    '''\n","    label_dict = {}\n","    for key in all_npz_dict:\n","        #Save gender and nationality in list\n","        label_dict[key] = [audio_class_dict[key.strip(\".npz\")][1], audio_class_dict[key.strip(\".npz\")][2]]\n","    return label_dict\n","\n","from sklearn.model_selection import train_test_split\n","\n","def split_train_validation(label_dict, feats):\n","    '''\n","    Function: Split data into training and validation sets\n","    Inputs:\n","        -label_dict: dictionary keyed by folder number, contains list with gender and nationality of that folder\n","        -feats: dictionary keyed by folder number of lists of 1x128 array melspectrograms\n","    Outputs:\n","        - X_train: list of lists containing melspectrogram data \n","        - y_train: list of 0 or 1 corresponding to female/male in X_train\n","        - X_dev: list of lists containing melspectrogram data\n","        - y_dev: list of 0 or 1 corresponding to female/male in X_dev\n","    '''\n","    X = []\n","    y = []\n","    for key in feats:\n","        for j, wave in enumerate(feats[key]):\n","            #Save array as list in X\n","            X.append(wave.tolist())\n","            #Label is 1 if male, 0 if female\n","            if label_dict[key][0] == 'm':\n","                y.append(1)\n","            else:\n","                y.append(0)\n","    #Use train_test_split to get training and validation sets, use validation of 30%\n","    #Used random state of 8 to seed (replace with any integer)\n","    X_train, X_dev, y_train, y_dev = train_test_split(X, y, test_size=0.3, random_state=8)\n","    return X_train, y_train, X_dev, y_dev\n","\n","def get_feats(filtered_npz, sr = 16000):\n","    '''\n","    Function: Get melspectrogram features for each wav file. Outputs 128-element vector\n","    Inputs: \n","        - filtered_npz: dictionary keyed by folder number, contains list of arrays representing wav files\n","        - sr: sampling rate (set to 16000 Hz)\n","    Outputs:\n","        - feats: dictionary keyed by folder number, contains list of 1x128 arrays representing melspec features for each wav\n","    '''\n","    feats = {}\n","    #Loop through all folders\n","    for key in filtered_npz:\n","        feats_list = []\n","        for j, wave in enumerate(filtered_npz[key]):\n","            feats_list.append(np.array([]))\n","            #Get melspectrogram features, give it time series data, take mean across 0 axis to get 1x128 vector\n","            melspec = np.mean(librosa.feature.melspectrogram(y=wave, sr=sr).T,axis=0)\n","            feats_list[j] = np.hstack((feats_list[j], melspec))\n","        feats[key] = feats_list\n","    return feats\n","\n","def prep_test(label_dict, feats):\n","    '''\n","    Function: prepare test data for evaluating accuracy of model\n","    Inputs:\n","        -label_dict_test: dictionary keyed by folder number for test set, contains list with gender and nationality of that folder\n","        -feats_test: dictionary keyed by folder number of lists of 1x128 array melspectrograms for test set\n","    Outputs:\n","        - X: list of lists containing melspectrogram data for test set\n","        - y: list of 0 or 1 corresponding to female/male in X\n","    '''\n","    X = []\n","    y = []\n","    for key in feats:\n","        for j, wave in enumerate(feats[key]):\n","            X.append(wave.tolist())\n","            if label_dict[key][0] == 'm':\n","                y.append(1)\n","            else:\n","                y.append(0)\n","    return X, y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y1R4oj7qJUx4"},"source":["#Get labels \n","label_dict_train = get_labels(train_npz_dict, audio_class_dict)\n","label_dict_test = get_labels(test_npz_dict, audio_class_dict)\n","#Filter signals\n","filtered_npz_train = filter_signals(train_npz_dict)\n","filtered_npz_test = filter_signals(test_npz_dict)\n","#Extract melspectrograms\n","feats_train = get_feats(filtered_npz_train)\n","feats_test = get_feats(filtered_npz_test)\n","#Get split data\n","X_train, y_train, X_dev, y_dev = split_train_validation(label_dict_train, feats_train)\n","#Get test data\n","X_test, y_test = prep_test(label_dict_test, feats_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KcCKf1XhJUx4"},"source":["#NN Model for Predicting Gender\n","\n","def create_model():\n","    '''\n","    Function: initialize neural network with 4 layers for training to predict gender. \n","    Contains 3 hidden layers with relu activation going from 256 nodes to 64 nodes (divide by 2 at each layer)\n","    Last layer uses sigmoid function with just one output neuron (0 or 1 to show female or male)\n","    Between each layer is dropout of 10%\n","    Inputs: None\n","    Outputs:\n","        - NNmodel: neural network framework\n","    '''\n","    #3 layers of dense networks using relu activation, 1 layer using sigmoid to get 1 output neuron (0 or 1)\n","    NNmodel = tf.keras.models.Sequential([\n","    tf.keras.layers.Dense(256, activation='relu'),\n","    tf.keras.layers.Dropout(0.1),\n","    tf.keras.layers.Dense(128, activation='relu'),\n","    tf.keras.layers.Dropout(0.1),\n","    tf.keras.layers.Dense(64, activation='relu'),\n","    tf.keras.layers.Dropout(0.1),\n","    tf.keras.layers.Dense(1, activation='sigmoid')])\n","    \n","    #Use binary crossentropy loss for binary classification (M/F)\n","    #Use accuracy for metrics\n","    #Use adam optimization: SGD method, use default lr of 0.001\n","    NNmodel.compile(loss=\"binary_crossentropy\", metrics=[\"accuracy\"], optimizer=\"adam\")\n","    \n","    return NNmodel"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pInpfI9-JUx5","outputId":"39f74af4-6daa-4698-8f14-c4b5c6a1c9cd"},"source":["gender_NNmodel = create_model()\n","\n","#Tensorboard to view losses and accuracies\n","tensorboard = TensorBoard(log_dir=\"logs\")\n","# Stop training if in 5 epochs accuracy is not improving, save weights that get best accuracy\n","early_stopping = EarlyStopping(mode=\"min\", patience=5, restore_best_weights=True)\n","\n","#Run on maximum of 75 epochs (usually only takes about 50 to converge)\n","#Use batch size of 64 (common based on size of data)\n","gender_NNmodel.fit(X_train, y_train, epochs=75, batch_size=64, validation_data=(X_dev, y_dev), callbacks=[tensorboard, early_stopping])\n","\n","#Get summary of model \n","gender_NNmodel.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/75\n","164/164 [==============================] - 30s 177ms/step - loss: 0.6618 - accuracy: 0.7093 - val_loss: 0.4579 - val_accuracy: 0.8143\n","Epoch 2/75\n","164/164 [==============================] - 1s 3ms/step - loss: 0.4514 - accuracy: 0.8329 - val_loss: 0.3586 - val_accuracy: 0.8655\n","Epoch 3/75\n","164/164 [==============================] - 1s 5ms/step - loss: 0.3439 - accuracy: 0.8706 - val_loss: 0.3130 - val_accuracy: 0.8706\n","Epoch 4/75\n","164/164 [==============================] - 1s 3ms/step - loss: 0.3045 - accuracy: 0.8733 - val_loss: 0.2989 - val_accuracy: 0.8836\n","Epoch 5/75\n","164/164 [==============================] - 1s 3ms/step - loss: 0.2667 - accuracy: 0.8896 - val_loss: 0.2725 - val_accuracy: 0.8965\n","Epoch 6/75\n","164/164 [==============================] - 1s 3ms/step - loss: 0.2484 - accuracy: 0.8957 - val_loss: 0.2712 - val_accuracy: 0.8954\n","Epoch 7/75\n","164/164 [==============================] - 1s 3ms/step - loss: 0.2345 - accuracy: 0.9057 - val_loss: 0.2512 - val_accuracy: 0.9039\n","Epoch 8/75\n","164/164 [==============================] - 1s 3ms/step - loss: 0.2178 - accuracy: 0.9146 - val_loss: 0.2533 - val_accuracy: 0.9010\n","Epoch 9/75\n","164/164 [==============================] - 1s 4ms/step - loss: 0.2183 - accuracy: 0.9095 - val_loss: 0.2234 - val_accuracy: 0.9155\n","Epoch 10/75\n","164/164 [==============================] - 1s 4ms/step - loss: 0.1945 - accuracy: 0.9191 - val_loss: 0.2392 - val_accuracy: 0.9122\n","Epoch 11/75\n","164/164 [==============================] - 1s 3ms/step - loss: 0.1811 - accuracy: 0.9272 - val_loss: 0.2384 - val_accuracy: 0.9171\n","Epoch 12/75\n","164/164 [==============================] - 1s 6ms/step - loss: 0.1761 - accuracy: 0.9306 - val_loss: 0.2174 - val_accuracy: 0.9242\n","Epoch 13/75\n","164/164 [==============================] - 1s 3ms/step - loss: 0.1638 - accuracy: 0.9354 - val_loss: 0.2433 - val_accuracy: 0.9213\n","Epoch 14/75\n","164/164 [==============================] - 1s 3ms/step - loss: 0.1425 - accuracy: 0.9456 - val_loss: 0.2181 - val_accuracy: 0.9200\n","Epoch 15/75\n","164/164 [==============================] - 1s 3ms/step - loss: 0.1569 - accuracy: 0.9397 - val_loss: 0.2486 - val_accuracy: 0.9209\n","Epoch 16/75\n","164/164 [==============================] - 1s 3ms/step - loss: 0.1314 - accuracy: 0.9507 - val_loss: 0.2522 - val_accuracy: 0.9256\n","Epoch 17/75\n","164/164 [==============================] - 1s 3ms/step - loss: 0.1261 - accuracy: 0.9506 - val_loss: 0.2566 - val_accuracy: 0.9231\n","Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense (Dense)                (None, 256)               33024     \n","_________________________________________________________________\n","dropout (Dropout)            (None, 256)               0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 128)               32896     \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 128)               0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 64)                8256      \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 64)                0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 1)                 65        \n","=================================================================\n","Total params: 74,241\n","Trainable params: 74,241\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RyLiPc2XJUx6","outputId":"a41c0870-22f4-4653-83af-1b9e203fc3f7"},"source":["#Calculate test accuracy and loss\n","test_loss, test_acc = gender_NNmodel.evaluate(X_test, y_test)\n","print(test_loss)\n","print(test_acc)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["141/141 [==============================] - 0s 1ms/step - loss: 0.2547 - accuracy: 0.9241\n","0.2547049820423126\n","0.9240703582763672\n"],"name":"stdout"}]}]}